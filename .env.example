# 客户端请求时允许通过请求的 API KEY，无需在当前环境变量当中手动添加 Bearer，目前只支持一个，未来可以升级为数组/toml/yaml 或专门的管理工具
ALLOW_API_KEY=your_api_key 

# 服务端跨域配置
# 允许访问的域名，多个域名使用逗号分隔(中间不能有空格)，例如：http://localhost:3000,https://chat.example.com
# 如果允许所有域名访问，则填写 *
ALLOW_ORIGINS=*

# DeepSeek API KEY，默认为 DeepSeek 官方 API，只支持 r1 系列模型（包括基于 llama 和 qwen 的密集模型，1.5b、7b、8b、14b、32b、70b、671b）
# 除了采用官网的 DeepSeek r1 外，还推荐以下：
# 1.SiliconFlow 的 deepseek-ai/DeepSeek-R1 获取 API KEY 的链接：https://cloud.siliconflow.cn/i/RXikvHE2 (点击此链接可以获得到 2000 万免费 tokens)
# 2.火山云托管的 deepseek r1 满血版，速度快，稳定
# 3.Groq 托管的 deepseek-r1-distill-llama-70b 获取 API KEY 的链接：https://console.groq.com/docs/models
# 4.本地 Ollama 运行的 DeepSeek r1 , 可以根据自己电脑的内存和显存大小而定，推荐 7b、8b、14b 最佳，获取链接：https://ollama.com
DEEPSEEK_API_KEY=your_deepseek_api_key
DEEPSEEK_API_URL=https://api.deepseek.com/v1/chat/completions #如果是siliconflow，则使用 https://api.siliconflow.cn/v1/chat/completions
DEEPSEEK_MODEL=deepseek-reasoner #如果是siliconflow，则使用 deepseek-ai/DeepSeek-R1

# DeepSeek推理过程格式配置
# 该变量用于区别返回体中推理过程的格式
# 目前支持两种格式：
# 1. Origin_Reasoning (支持 reasoning_content 字段返回) (DeepSeek官方 deepseek-reasoner 模型、 SiliconFlow 的 deepseek-ai/DeepSeek-R1 模型、火山云的 DeepSeek R1 模型均支持)
# 2. <think></think> 标签格式（通常是通过 deepseek r1 蒸馏过的模型采用这种格式，包括各个平台托管的基于 llama 和 qwen 的密集模型，比如 7b、8b、14b、32b、70b 的版本）
# 填写true表示使用 Origin_Reasoning 格式，填写false表示使用 <think></think> 标签格式
IS_ORIGIN_REASONING=true

# Claude API KEY，默认为 Claude 官方 API
CLAUDE_API_KEY=your_claude_api_key

# Claude 模型
# 如留空不填则使用客户端请求体中的model字段, 如果留空不填且客户端请求体中也没有model字段，则默认使用 claude-3-5-sonnet-20241022
CLAUDE_MODEL=claude-3-5-sonnet-20241022

# Claude Provider
# 若使用官方则填 anthropic
# 若使用中转平台如 OpenRouter 或国内基于 OneAPI 的中转平台则填oneapi
CLAUDE_PROVIDER=anthropic

# 如果使用 OpenRouter，这里填写 OpenRouter 的 API URL https://openrouter.ai/api/v1/chat/completions, 
# 如果使用中转平台则填写相应的 API URL: 例如 https://api.oneapi.com/v1/chat/completions
# 默认为 Anthropic 的 API URL https://api.anthropic.com/v1/messages
CLAUDE_API_URL=https://api.anthropic.com/v1/messages

# Gemini 模型
OPENAI_COMPOSITE_API_KEY=your_api_key
OPENAI_COMPOSITE_API_URL=https://generativelanguage.googleapis.com/v1beta/openai/chat/completions
OPENAI_COMPOSITE_MODEL=gemini-2.0-pro-exp

# 日志配置
# 可选值：DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Web配置界面设置
# 是否启用Web配置管理界面
# 启用前(false): 所有配置必须在环境变量或.env文件中设置，修改需重启服务才能生效
# 启用后(true): 配置从CONFIG_FILE_PATH指定的YAML/JSON文件中读取，可通过Web界面实时修改，无需重启服务
# 启用后系统将使用模型映射机制来管理Gemini等OpenAI兼容模型。环境变量中的OPENAI_COMPOSITE_MODEL设置将被忽略，
# 请通过Web界面的模型映射功能进行配置，可实现更灵活的模型别名和映射管理。
ENABLE_WEB_CONFIG=false

# Web配置界面端口，默认值8080，可自定义
WEB_CONFIG_PORT=8080

# Web配置界面访问路径，默认为/admin，如有修改请同步修改templates/index.html中的 basePath （第 900 行）
# 例如：http://your-server:8080/admin
WEB_CONFIG_PATH=/admin

# Web配置界面认证凭据 (启用Web配置界面后必须设置)
WEB_CONFIG_USERNAME=admin
WEB_CONFIG_PASSWORD=your_secure_password
# JWT 密钥，用于生成和验证令牌，建议使用随机字符串
WEB_CONFIG_SECRET_KEY=your-secret-key-here
# JWT 令牌过期时间（分钟）
WEB_CONFIG_TOKEN_EXPIRE_MINUTES=60*24*7

# 配置持久化路径，支持YAML/JSON格式
# 启用Web配置后，所有通过Web界面更改的配置将保存到此文件
# 当服务重启时，会从此文件加载配置而非环境变量
# 模型映射也会从此文件中加载，并可通过Web界面实时添加、修改和删除
CONFIG_FILE_PATH=./config/app_config.yaml


